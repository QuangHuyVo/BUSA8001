{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUSA8001- Programming Task 1  \n",
    "\n",
    "**Assignment Points**: 100  \n",
    "**Submission**: Provide your answers in this notebook and submit it via iLearn\n",
    "\n",
    "- Where a question requires a written answer provide your solution in Markdown in the cells under each question.\n",
    "- Comment out your print statements unless you are explicitly asked to print your output. \n",
    "- 5 marks will be deducted for printed outputs that are not asked for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the Assignment\n",
    "\n",
    "- For this assignment there are two files in the `data` folder `credit_record.csv` and `application_record.csv` where bank clients are related by the `ID` column.\n",
    "\n",
    "- In `application_record.csv` we have the following variables\n",
    "\n",
    "| Feature Name         | Explanation     | Additional Remarks |\n",
    "|--------------|-----------|-----------|\n",
    "| ID | Randomly allocated client number      |         |\n",
    "| AMT_INCOME   | Annual income  |  |\n",
    "| NAME_INCOME_TYPE   | Income Source |  |\n",
    "| NAME_EDUCATION_TYPE   | Level of Education  |  |\n",
    "| CODE_GENDER   | Applicant's Gender   |  |\n",
    "| FLAG_OWN_CAR | Car Ownership |  | \n",
    "| CNT_CHILDREN | Number of Children | |\n",
    "| FLAG_OWN_REALTY | Real Estate Ownership | | \n",
    "| NAME_FAMILY_STATUS | Relationship Status | | \n",
    "| NAME_HOUSING_TYPE | Housing Type | | \n",
    "| DAYS_BIRTH | No. of Days | Count backwards from current day (0), -1 means yesterday\n",
    "| DAYS_EMPLOYED | No. of Days | Count backwards from current day (0). If positive, it means the person is currently unemployed.\n",
    "| FLAG_MOBIL | Mobile Phone Ownership | | \n",
    "| FLAG_WORK_PHONE | Work Phone Ownership | | \n",
    "| FLAG_PHONE | Landline Phone Ownership | | \n",
    "| FLAG_EMAIL | Landline Phone Ownership | | \n",
    "| OCCUPATION_TYPE | Occupation | | \n",
    "| CNT_FAM_MEMBERS | Count of Family Members | |\n",
    "\n",
    "\n",
    "\n",
    "- In `credit_record.csv` we have the following variables\n",
    "\n",
    "\n",
    "| Feature Name         | Explanation     | Additional Remarks |\n",
    "|--------------|-----------|-----------|\n",
    "| ID | Randomly allocated client number | |\n",
    "| MONTHS_BALANCE | Number of months in the past from now when STATUS is measured | 0 = current month, -1 = last month, -2 = two months ago, etc.|\n",
    "| STATUS | Number of days a payment is past due | 0: 1-29 days past due 1: 30-59 days past due 2: 60-89 days overdue 3: 90-119 days overdue 4: 120-149 days overdue 5: Overdue or bad debts, write-offs for more than 150 days C: paid off that month X: No loan for the month |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Task 1: Reading, Summarising and Cleaning Data (Total Marks: 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** \n",
    "\n",
    "1. Import the `application_record.csv` and `credit_record.csv` files from `data` folder into pandas DataFrames named `df_application` and `df_credit`, respectively. (1 mark)\n",
    "\n",
    "2. How many rows are there in `df_application` and `df_credit`, respectively? Provide your answers with print() and state them in Markdown text. (1 mark)\n",
    "\n",
    "3. How many unique bank clients are there in `df_application` and `df_credit`? Provide your answers with print() and state them in Markdown text. (1 mark)\n",
    "\n",
    "4. Add the records from `df_credit` to `df_application` by merging the data from the two DataFrames on the `ID` column, and output the joint data into a new DataFrame named `df`. Hint: Use `merge` function from pandas by setting `how` parameter to `inner` (4 marks) \n",
    "\n",
    "5. How many rows and how many unique clients are there now in `df`? (1 mark)\n",
    "\n",
    "6. How are multiple rows for each `ID` in `df` different? Answer in Markdown text. (2 mark) \n",
    "\n",
    "(10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- provide your code here -----\n",
    "# Question 1: \n",
    "# 1.Import the application_record.csv and credit_record.csv files from data folder into pandas DataFrames \n",
    "# named df_application and df_credit, respectively.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV files\n",
    "df_application = pd.read_csv('data/application_record.csv')\n",
    "df_credit = pd.read_csv('data/credit_record.csv')\n",
    "\n",
    "#df_application.head(10)\n",
    "#df_credit.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df_application: 438445\n",
      "Number of rows in df_credit: 1047185\n"
     ]
    }
   ],
   "source": [
    "# 2. How many rows are there in df_application and df_credit, respectively? \n",
    "# Provide your answers with print() and state them in Markdown text.\n",
    "\n",
    "print(\"Number of rows in df_application:\", df_application.shape[0])\n",
    "print(\"Number of rows in df_credit:\", df_credit.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "2.\n",
    "\n",
    "Number of rows in df_application: 438445\n",
    "\n",
    "Number of rows in df_credit:1047185"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique bank clients in df_application: 438398\n",
      "Number of unique bank clients in df_credit: 45924\n"
     ]
    }
   ],
   "source": [
    "# 3. How many unique bank clients are there in df_application and df_credit? \n",
    "# Provide your answers with print() and state them in Markdown text.\n",
    "\n",
    "print(\"Number of unique bank clients in df_application:\", df_application['ID'].nunique())\n",
    "print(\"Number of unique bank clients in df_credit:\", df_credit['ID'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "3.\n",
    "\n",
    "Number of unique bank clients in df_application: 438398\n",
    "\n",
    "Number of unique bank clients in df_credit:45924"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Add the records from df_credit to df_application by merging the data from the two DataFrames on the ID column, \n",
    "# and output the joint data into a new DataFrame named df \n",
    "# Hint: Use merge function from pandas by setting how parameter to inner (4 marks)\n",
    "\n",
    "df = pd.merge(df_application, df_credit, on='ID', how='inner')\n",
    "\n",
    "#df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df: 776325\n",
      "Number of unique clients in df: 36396\n"
     ]
    }
   ],
   "source": [
    "# 5. How many rows and how many unique clients are there now in df?\n",
    "\n",
    "print(\"Number of rows in df:\", df.shape[0])\n",
    "print(\"Number of unique clients in df:\", df['ID'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. How are multiple rows for each ID in df different? Answer in Markdown text.\n",
    "\n",
    "Although these IDs have same information like gender, income type, education type, etc., some IDs have different values in  \"MONTH_BALANCE\" AND 'STATUS' columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- provide your written answer here ----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Question 2.**\n",
    "\n",
    "1. Change the values of `STATUS` in `df` according to the following mapping: {C, X, 0} -> 0 and {1, 2, 3, 4, 5} -> 1 making sure that the new values of 0 and 1 are encoded as integers. (2 marks)\n",
    "\n",
    "2. Create a new *numpy* array called `list_of_past_due` that includes the unique ID numbers of clients whose `STATUS = 1` at any point during the last 12 months (hint: count the current month as the first month). (2 marks) \n",
    "\n",
    "3. Create a new DataFrame called `df_final` that contains the rows of `df` for which the `ID` is in `list_of_past_due`, keeping only one row for each `ID` (hint: keep the first duplicate row). How many rows do you have in `df_final`? Answer using both print() function and in Markdown text. (hint: find out about `isin()` function in pandas.) (2 marks)\n",
    "\n",
    "4. Add a new column `y = 1` for all the rows in `df_final`. (1 marks)\n",
    "\n",
    "5. Increase `df_final` to a total of 4,500 rows by adding rows from `df` with unique `ID`s which are not in `list_of_past_due`. To do this start adding the rows from the beginning of `df`. (hint: learn what `~`, i.e. tilde sign, does in pandas). (2 marks) \n",
    "\n",
    "6. Fill the missing values of `y` in `df_final` with zeros. Remove `STATUS` and `MONTHS_BALANCE` from `df_final`. (1 mark)\n",
    "\n",
    "(10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- provide your code here -----\n",
    "# Question 2:\n",
    "# 1. Change the values of STATUS in df according to the following mapping: {C, X, 0} -> 0 \n",
    "# and {1, 2, 3, 4, 5} -> 1 making sure that the new values of 0 and 1 are encoded as integers.\n",
    "\n",
    "status_mapping = {'C': 0, 'X': 0, '0': 0, '1': 1, '2': 1, '3': 1, '4': 1, '5': 1}\n",
    "df['STATUS'] = df['STATUS'].map(status_mapping).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create a new numpy array called list_of_past_due \n",
    "# that includes the unique ID numbers of clients whose STATUS = 1 at any point during the last 12 months \n",
    "# (hint: count the current month as the first month).\n",
    "\n",
    "recent_12_months = df[df['MONTHS_BALANCE'] >= -11]\n",
    "list_of_past_due = np.array(recent_12_months[recent_12_months['STATUS'] == 1]['ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1737\n"
     ]
    }
   ],
   "source": [
    "print(len(list_of_past_due))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create a new DataFrame called df_final that contains the rows of df for which the ID is in list_of_past_due, \n",
    "# keeping only one row for each ID (hint: keep the first duplicate row). \n",
    "# How many rows do you have in df_final? Answer using both print() function and in Markdown text. (hint: find out about isin() function in pandas.) \n",
    "\n",
    "df_final = df[df['ID'].isin(list_of_past_due)].drop_duplicates(subset=['ID'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df_final: 1737\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows in df_final:\", df_final.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Number of rows in df_final: 1737"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Add a new column y = 1 for all the rows in df_final. \n",
    "\n",
    "df_final['y'] = 1\n",
    "#df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Increase df_final to a total of 4,500 rows by adding rows from df with unique IDs which are not in list_of_past_due. \n",
    "# To do this start adding the rows from the beginning of df. (hint: learn what ~, i.e. tilde sign, does in pandas).\n",
    "\n",
    "remain_id = df[~df['ID'].isin(list_of_past_due)]['ID'].unique()\n",
    "add_rows = df[df['ID'].isin(remain_id)].drop_duplicates(subset=['ID'], keep='first')\n",
    "\n",
    "df_final = pd.concat([df_final, add_rows]).head(4500)\n",
    "#df_final.head(1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Fill the missing values of y in df_final with zeros. Remove STATUS and MONTHS_BALANCE from df_final.\n",
    "\n",
    "df_final['y'] = df_final['y'].fillna(0).astype(int)\n",
    "df_final = df_final.drop(columns=['STATUS', 'MONTHS_BALANCE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- provide your written answer here ----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 3**. \n",
    "1. Delete `ID` column from `df_final` and reset its index. (1 marks)\n",
    "2. Assuming that `NAME_EDUCATION_TYPE` is the only ordinal variable in `df_final`, which variables are numeric and which ones are nominal? Answer this question by copying and completing the following table (6 marks)\n",
    "\n",
    "|Variable type|Numbers of features|Features' list|\n",
    "| --- | --- | --- |\n",
    "|Numeric:|||\n",
    "|Ordinal:|1| NAME_EDUCATION_TYPE |\n",
    "|Nominal:|||\n",
    "\n",
    "3. Using appropriate functions find and comment on the missing values in `df_final` (3 marks)   \n",
    "\n",
    "(10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- provide your code here ----\n",
    "# Question 3: \n",
    "# 1. Delete ID column from df_final and reset its index. \n",
    "\n",
    "df_final = df_final.drop(columns=['ID']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>NAME_HOUSING_TYPE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>FLAG_MOBIL</th>\n",
       "      <th>FLAG_WORK_PHONE</th>\n",
       "      <th>FLAG_PHONE</th>\n",
       "      <th>FLAG_EMAIL</th>\n",
       "      <th>OCCUPATION_TYPE</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-10031</td>\n",
       "      <td>-1469</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-16670</td>\n",
       "      <td>-5364</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Security staff</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>-15519</td>\n",
       "      <td>-3234</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>-15519</td>\n",
       "      <td>-3234</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>Rented apartment</td>\n",
       "      <td>-15519</td>\n",
       "      <td>-3234</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME  \\\n",
       "0           F            N               Y           NaN    157500.0   \n",
       "1           M            Y               Y           NaN    360000.0   \n",
       "2           F            N               Y           0.0    297000.0   \n",
       "3           F            N               Y           0.0    297000.0   \n",
       "4           F            N               Y           0.0    297000.0   \n",
       "\n",
       "       NAME_INCOME_TYPE            NAME_EDUCATION_TYPE    NAME_FAMILY_STATUS  \\\n",
       "0               Working  Secondary / secondary special               Married   \n",
       "1  Commercial associate                            NaN               Married   \n",
       "2  Commercial associate                            NaN  Single / not married   \n",
       "3  Commercial associate                            NaN  Single / not married   \n",
       "4  Commercial associate                            NaN  Single / not married   \n",
       "\n",
       "   NAME_HOUSING_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  FLAG_MOBIL  FLAG_WORK_PHONE  \\\n",
       "0  House / apartment      -10031          -1469           1                0   \n",
       "1  House / apartment      -16670          -5364           1                0   \n",
       "2   Rented apartment      -15519          -3234           1                0   \n",
       "3   Rented apartment      -15519          -3234           1                0   \n",
       "4   Rented apartment      -15519          -3234           1                0   \n",
       "\n",
       "   FLAG_PHONE  FLAG_EMAIL OCCUPATION_TYPE  CNT_FAM_MEMBERS  y  \n",
       "0           1           0        Laborers                2  1  \n",
       "1           1           0  Security staff                2  1  \n",
       "2           0           0        Laborers                1  1  \n",
       "3           0           0        Laborers                1  1  \n",
       "4           0           0        Laborers                1  1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming that NAME_EDUCATION_TYPE is the only ordinal variable in df_final, \n",
    "# which variables are numeric and which ones are nominal? \n",
    "# Answer this question by copying and completing the following table\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Variable type|Numbers of features|Features' list|\n",
    "| --- | --- | --- |\n",
    "|Numeric:|10| CNT_CHILDREN, AMT_INCOME, DAYS_BIRTH, DAYS_EMPLOYED, FLAG_MOBIL, FLAG_WORK_PHONE, FLAG_PHONE, FLAG_EMAIL, CNT_FAM_MEMBERS, y |\n",
    "|Ordinal:|1| NAME_EDUCATION_TYPE |\n",
    "|Nominal:|7| CODE_GENDER, FLAG_OWN_CAR, FLAG_OWN_REALTY, NAME_INCOME_TYPE, NAME_FAMILY_STATUS, NAME_HOUSING_TYPE, OCCUPATION_TYPE |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODE_GENDER               0\n",
      "FLAG_OWN_CAR              0\n",
      "FLAG_OWN_REALTY           0\n",
      "CNT_CHILDREN             74\n",
      "AMT_INCOME                0\n",
      "NAME_INCOME_TYPE          0\n",
      "NAME_EDUCATION_TYPE    1831\n",
      "NAME_FAMILY_STATUS        0\n",
      "NAME_HOUSING_TYPE         0\n",
      "DAYS_BIRTH                0\n",
      "DAYS_EMPLOYED             0\n",
      "FLAG_MOBIL                0\n",
      "FLAG_WORK_PHONE           0\n",
      "FLAG_PHONE                0\n",
      "FLAG_EMAIL                0\n",
      "OCCUPATION_TYPE        1354\n",
      "CNT_FAM_MEMBERS           0\n",
      "y                         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3. Using appropriate functions find and comment on the missing values in df_final \n",
    "\n",
    "missing_values = df_final.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- provide your written answer here ----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Task 2: Imputing missing values and dealing with categorical features (Total Marks: 30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** \n",
    "1. Use an appropriate `pandas` function to impute missing values in `df_final` (15 marks)\n",
    "    - Take into consideration the type of each variable and the best practices we discussed in class/lecture notes\n",
    "\n",
    "(Total: 15 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- provide your code here -----\n",
    "\n",
    "#Question 4.\n",
    "\n",
    "#Use an appropriate pandas function to impute missing values in df_final (15 marks)\n",
    "#Take into consideration the type of each variable and the best practices we discussed in class/lecture notes\n",
    "\n",
    "# Impute numeric variable CNT_CHILDREN with median\n",
    "df_final['CNT_CHILDREN'].fillna(df_final['CNT_CHILDREN'].median(), inplace=True)\n",
    "\n",
    "# Impute ordinal variable NAME_EDUCATION_TYPE with mode (most frequent value)\n",
    "df_final['NAME_EDUCATION_TYPE'].fillna(df_final['NAME_EDUCATION_TYPE'].mode()[0], inplace=True)\n",
    "\n",
    "# Impute nominal variable OCCUPATION_TYPE with 'NA'\n",
    "df_final['OCCUPATION_TYPE'].fillna('NA', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 5**. Convert the values in `NAME_EDUCATION_TYPE` as follows\n",
    "- Lower secondary -> 1\n",
    "- Secondary / secondary special -> 2\n",
    "- Incomplete higher -> 3\n",
    "- Higher education -> 4\n",
    "\n",
    "\n",
    "(Total: 5 marks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- provide your code here -----\n",
    "#Question 5. Convert the values in NAME_EDUCATION_TYPE as follows\n",
    "\n",
    "#Lower secondary -> 1\n",
    "#Secondary / secondary special -> 2\n",
    "#Incomplete higher -> 3\n",
    "#Higher education -> 4\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder(categories=[['Lower secondary', \n",
    "                                              'Secondary / secondary special', \n",
    "                                              'Incomplete higher', \n",
    "                                              'Higher education']])\n",
    "# Reshape the data to use with OrdinalEncoder\n",
    "df_final['NAME_EDUCATION_TYPE'] = ordinal_encoder.fit_transform(df_final[['NAME_EDUCATION_TYPE']])\n",
    "\n",
    "# Increment values to match your desired encoding (1 to 4 instead of 0 to 3)\n",
    "df_final['NAME_EDUCATION_TYPE'] = df_final['NAME_EDUCATION_TYPE'].astype(int) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 6**. \n",
    "\n",
    "Add dummy variables to `df_final` for all of the nominal features which are currently stored as string (text). \n",
    "- Make sure to delete the original variables from the dataframe\n",
    "- Drop the first column from each set of created dummy variable, i.e. for each feature\n",
    "\n",
    "\n",
    "\n",
    "(Total: 10 marks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- provide your code here -\n",
    "#Question 6.\n",
    "\n",
    "#Add dummy variables to df_final for all of the nominal features which are currently stored as string (text).\n",
    "\n",
    "#Make sure to delete the original variables from the dataframe\n",
    "#Drop the first column from each set of created dummy variable, i.e. for each feature\n",
    "\n",
    "nominal_columns = ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', \n",
    "                   'NAME_INCOME_TYPE', 'NAME_FAMILY_STATUS', \n",
    "                   'NAME_HOUSING_TYPE', 'OCCUPATION_TYPE']\n",
    "\n",
    "# Create dummy variables and drop the original columns\n",
    "df_final = pd.get_dummies(df_final, columns=nominal_columns, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4500 entries, 0 to 4499\n",
      "Data columns (total 45 columns):\n",
      " #   Column                                   Non-Null Count  Dtype  \n",
      "---  ------                                   --------------  -----  \n",
      " 0   CNT_CHILDREN                             4500 non-null   float64\n",
      " 1   AMT_INCOME                               4500 non-null   float64\n",
      " 2   NAME_EDUCATION_TYPE                      4500 non-null   int32  \n",
      " 3   DAYS_BIRTH                               4500 non-null   int64  \n",
      " 4   DAYS_EMPLOYED                            4500 non-null   int64  \n",
      " 5   FLAG_MOBIL                               4500 non-null   int64  \n",
      " 6   FLAG_WORK_PHONE                          4500 non-null   int64  \n",
      " 7   FLAG_PHONE                               4500 non-null   int64  \n",
      " 8   FLAG_EMAIL                               4500 non-null   int64  \n",
      " 9   CNT_FAM_MEMBERS                          4500 non-null   int64  \n",
      " 10  y                                        4500 non-null   int32  \n",
      " 11  CODE_GENDER_M                            4500 non-null   uint8  \n",
      " 12  FLAG_OWN_CAR_Y                           4500 non-null   uint8  \n",
      " 13  FLAG_OWN_REALTY_Y                        4500 non-null   uint8  \n",
      " 14  NAME_INCOME_TYPE_Pensioner               4500 non-null   uint8  \n",
      " 15  NAME_INCOME_TYPE_State servant           4500 non-null   uint8  \n",
      " 16  NAME_INCOME_TYPE_Student                 4500 non-null   uint8  \n",
      " 17  NAME_INCOME_TYPE_Working                 4500 non-null   uint8  \n",
      " 18  NAME_FAMILY_STATUS_Married               4500 non-null   uint8  \n",
      " 19  NAME_FAMILY_STATUS_Separated             4500 non-null   uint8  \n",
      " 20  NAME_FAMILY_STATUS_Single / not married  4500 non-null   uint8  \n",
      " 21  NAME_FAMILY_STATUS_Widow                 4500 non-null   uint8  \n",
      " 22  NAME_HOUSING_TYPE_House / apartment      4500 non-null   uint8  \n",
      " 23  NAME_HOUSING_TYPE_Municipal apartment    4500 non-null   uint8  \n",
      " 24  NAME_HOUSING_TYPE_Office apartment       4500 non-null   uint8  \n",
      " 25  NAME_HOUSING_TYPE_Rented apartment       4500 non-null   uint8  \n",
      " 26  NAME_HOUSING_TYPE_With parents           4500 non-null   uint8  \n",
      " 27  OCCUPATION_TYPE_Cleaning staff           4500 non-null   uint8  \n",
      " 28  OCCUPATION_TYPE_Cooking staff            4500 non-null   uint8  \n",
      " 29  OCCUPATION_TYPE_Core staff               4500 non-null   uint8  \n",
      " 30  OCCUPATION_TYPE_Drivers                  4500 non-null   uint8  \n",
      " 31  OCCUPATION_TYPE_HR staff                 4500 non-null   uint8  \n",
      " 32  OCCUPATION_TYPE_High skill tech staff    4500 non-null   uint8  \n",
      " 33  OCCUPATION_TYPE_IT staff                 4500 non-null   uint8  \n",
      " 34  OCCUPATION_TYPE_Laborers                 4500 non-null   uint8  \n",
      " 35  OCCUPATION_TYPE_Low-skill Laborers       4500 non-null   uint8  \n",
      " 36  OCCUPATION_TYPE_Managers                 4500 non-null   uint8  \n",
      " 37  OCCUPATION_TYPE_Medicine staff           4500 non-null   uint8  \n",
      " 38  OCCUPATION_TYPE_NA                       4500 non-null   uint8  \n",
      " 39  OCCUPATION_TYPE_Private service staff    4500 non-null   uint8  \n",
      " 40  OCCUPATION_TYPE_Realty agents            4500 non-null   uint8  \n",
      " 41  OCCUPATION_TYPE_Sales staff              4500 non-null   uint8  \n",
      " 42  OCCUPATION_TYPE_Secretaries              4500 non-null   uint8  \n",
      " 43  OCCUPATION_TYPE_Security staff           4500 non-null   uint8  \n",
      " 44  OCCUPATION_TYPE_Waiters/barmen staff     4500 non-null   uint8  \n",
      "dtypes: float64(2), int32(2), int64(7), uint8(34)\n",
      "memory usage: 501.1 KB\n"
     ]
    }
   ],
   "source": [
    "df_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Task 3 Preparing X and y arrays (Total Marks: 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7**. \n",
    "\n",
    "1. Create a numpy array named `y` from the `y` column of `df_final` making sure that the values of the array `y` are stored as integers (3 marks)   \n",
    "2. Create a numpy array named `X`  from all the remaining features in `df_final` (2 marks)   \n",
    "\n",
    "(Total: 5 Marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (4500, 44)\n",
      "Shape of y: (4500,)\n"
     ]
    }
   ],
   "source": [
    "# ---- provide your code here -----\n",
    "#Question 7.\n",
    "\n",
    "#Create a numpy array named y from the y column of df_final making sure that the values of the array y are stored as integers (3 marks)\n",
    "#Create a numpy array named X from all the remaining features in df_final (2 marks)\n",
    "\n",
    "# Create a numpy array 'y' from the 'y' column and ensure it's stored as integers\n",
    "y = np.array(df_final['y'].astype(int))\n",
    "\n",
    "# Create a numpy array 'X' from all the remaining features\n",
    "# Drop the 'y' column from df_final and convert the remaining columns to a NumPy array using np.array\n",
    "X = np.array(df_final.drop(columns=['y']))\n",
    "\n",
    "# Check the shapes of X and y\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"width:25%;margin-left:0;\"> \n",
    "\n",
    "**Question 8**. \n",
    "\n",
    "1. Use an appropriate scikit-learn library we used in class to create `y_train`, `y_test`, `X_train` and `X_test` by splitting the data into 75% train and 25% test datasets (2.5 marks) \n",
    "    - Set random_state to 8 and stratify the subsamples so that train and test datasets have roughly equal proportions of the target's class labels \n",
    "2. Standardise the data using `StandardScaler` library (2.5 marks)   \n",
    "\n",
    "(Total: 5 marks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (3375, 44)\n",
      "Shape of X_test: (1125, 44)\n",
      "Shape of y_train: (3375,)\n",
      "Shape of y_test: (1125,)\n"
     ]
    }
   ],
   "source": [
    "# ---- provide your code here -----\n",
    "# Question 8.\n",
    "\n",
    "#Use an appropriate scikit-learn library we used in class to create y_train, y_test, X_train and X_test by splitting the data into 75% train and 25% test datasets (2.5 marks)\n",
    "#Set random_state to 8 and stratify the subsamples so that train and test datasets have roughly equal proportions of the target's class labels\n",
    "#Standardise the data using StandardScaler library (2.5 marks)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=8, stratify=y)\\\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform it\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Apply the same transformation to the test data\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#print(\"First few rows of standardized X_train:\", X_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Task 4. Logistic Regression and Random Forest Classifiers and Accuracies (Total Marks: 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9**. \n",
    "\n",
    "1. Train a Logistic Regression Classifier on standardised data (5 marks)\n",
    "    - Set `random_state` to 10 (don't change any other parameters)\n",
    "    - Compute and print training and test dataset accuracies   \n",
    "2. Train a Random Forest Classifier on standardised data (5 marks)\n",
    "    - Set `random_state` to 10 (don't change any other parameters)\n",
    "    - Compute and print training and test dataset accuracies\n",
    "\n",
    "When printing accuracies round the values to three decimal places.      \n",
    "\n",
    "(Total: 10 marks)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Training Accuracy: 0.657\n",
      "Logistic Regression Test Accuracy: 0.654\n"
     ]
    }
   ],
   "source": [
    "# ---- provide your code here -----\n",
    "\n",
    "#Question 9.\n",
    "\n",
    "# 1. Train a Logistic Regression Classifier on standardised data (5 marks)\n",
    "#Set random_state to 10 (don't change any other parameters)\n",
    "#Compute and print training and test dataset accuracies\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the Logistic Regression classifier with a fixed random state\n",
    "log_reg = LogisticRegression(random_state=10)\n",
    "\n",
    "# Train the classifier on the standardized training data\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the training and test data\n",
    "y_train_pred = log_reg.predict(X_train)\n",
    "y_test_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Calculate training and test accuracies\n",
    "accuracy_train_log_reg = accuracy_score(y_train, y_train_pred)\n",
    "accuracy_test_log_reg = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the accuracies rounded to three decimal places\n",
    "print(\"Logistic Regression Training Accuracy:\", round(accuracy_train_log_reg, 3))\n",
    "print(\"Logistic Regression Test Accuracy:\", round(accuracy_test_log_reg, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Training Accuracy: 0.977\n",
      "Random Forest Test Accuracy: 0.897\n"
     ]
    }
   ],
   "source": [
    "#3. Train a Random Forest Classifier on standardised data (5 marks)\n",
    "#Set random_state to 10 (don't change any other parameters)\n",
    "#Compute and print training and test dataset accuracies\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest classifier with a fixed random state\n",
    "random_forest = RandomForestClassifier(random_state=10)\n",
    "\n",
    "# Train the classifier on the standardized training data\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the training and test data\n",
    "y_train_pred_rf = random_forest.predict(X_train)\n",
    "y_test_pred_rf = random_forest.predict(X_test)\n",
    "\n",
    "# Calculate training and test accuracies\n",
    "accuracy_train_rf = accuracy_score(y_train, y_train_pred_rf)\n",
    "accuracy_test_rf = accuracy_score(y_test, y_test_pred_rf)\n",
    "\n",
    "# Print the accuracies rounded to three decimal places\n",
    "print(\"Random Forest Training Accuracy:\", round(accuracy_train_rf, 3))\n",
    "print(\"Random Forest Test Accuracy:\", round(accuracy_test_rf, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 10**. \n",
    "\n",
    "a) Comment and compare the training and test accuracies for each classifier computed in Question 9. What can we say about the extent of overfitting for each classifier? (5 marks)   \n",
    "b) Comment and compare the accuracies across the two classifiers. Which classifier provides better forecasts? (5 marks)   \n",
    "c) What can you say about the presence of nonlinearities in the dataset? (10 marks)   \n",
    "\n",
    "(Total: 20 marks)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Part a\n",
    "\n",
    "Logistic Regression:\n",
    "\n",
    "Training Accuracy: 0.657\n",
    "Test Accuracy: 0.654\n",
    "The training and test accuracies for the Logistic Regression model are quite close, indicating minimal overfitting. The model generalizes well to unseen data (test set). However, the overall accuracy is moderately low, suggesting that the model may be underfitting the dataset or that the linear model may not be capturing all the complexities of the data.\n",
    "\n",
    "Random Forest:\n",
    "\n",
    "Training Accuracy: 0.977\n",
    "Test Accuracy: 0.897\n",
    "The Random Forest classifier shows a high training accuracy but a lower test accuracy. The discrepancy between these two metrics suggests some degree of overfitting. The model performs exceptionally well on the training data, likely capturing intricate patterns that do not generalize as effectively on the test data. However, even with this overfitting, the test accuracy is significantly higher than that of the Logistic Regression model.\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "### Part b\n",
    "\n",
    "Random Forest provides better forecasts than Logistic Regression, as evidenced by its higher test accuracy (0.897 vs. 0.654). This indicates that the Random Forest model is more capable of handling the complexity and variability in the data.\n",
    "Logistic Regression, while not overfitting, shows lower accuracy both in training and testing, which might indicate it is too simplistic a model to capture the necessary patterns in the data for more accurate predictions.\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "### Part c\n",
    "\n",
    "The performance differences between the Logistic Regression and Random Forest classifiers can provide insights into the nature of the dataset:\n",
    "\n",
    "Nonlinear Relationships: The fact that the Random Forest, which can handle complex nonlinear relationships between features, significantly outperforms Logistic Regression suggests the presence of nonlinearities in the data. Logistic Regression's assumption of linearity appears to be insufficient for modeling the underlying relationships effectively.\n",
    "Model Suitability: The superior performance of Random Forest indicates that the dataset benefits from a model that can capture interactions and nonlinearities. This is typical in real-world scenarios where many factors interact in complex ways that a linear model like Logistic Regression cannot adequately capture.\n",
    "Data Complexity: The high training accuracy of Random Forest also implies that there are likely meaningful patterns in the data, which this model can learn but may also overfit. This suggests that careful feature selection, parameter tuning, or the application of regularization techniques might be necessary to optimize model performance further without losing the ability to generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
